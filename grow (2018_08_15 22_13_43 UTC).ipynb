{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#import theano\n",
    "import time\n",
    "import deap\n",
    "from itertools import izip\n",
    "import random\n",
    "from autograd import grad\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.linalg as LA\n",
    "binarylist = [1, 0]\n",
    "xorinputs = []\n",
    "xoroutputs = []\n",
    "for x in binarylist:\n",
    "    for y in binarylist:\n",
    "        xorinputs.append(np.array([x,y]))\n",
    "        xoroutputs.append(np.array([x^y]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "         253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "         253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "         253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "         205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "          90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "         190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "         253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "         241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "         148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "         253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "         253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "         195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "          11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0]], dtype=uint8))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mnist\n",
    "\n",
    "#format is (label as int, 2D image array)\n",
    "TrainingSet = list(mnist.read(dataset = \"training\")) \n",
    "TestingSet = list(mnist.read(dataset = \"testing\"))\n",
    "TrainingSet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21,)\n",
      "[ 0.  1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python2.7/site-packages/sklearn/preprocessing/data.py:167: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "/usr/lib64/python2.7/site-packages/sklearn/preprocessing/data.py:184: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "# def labelToArray(x):\n",
    "#     blank = [0] * 10\n",
    "#     blank[x] = 1\n",
    "#     return np.array(blank)\n",
    "# TrainingSetList = list(TrainingSet)\n",
    "# TestSetList = list(TestingSet)\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "\n",
    "trainingFilePath = \"numerai_training_data.csv\"\n",
    "tournamentFilePath = \"numerai_tournament_data.csv\"\n",
    "\n",
    "\n",
    "def readTraining(splitforTesting = True):\n",
    "    trainingFile = open(trainingFilePath, 'rb')\n",
    "    trainingFeatures = []\n",
    "    trainingLabels = []\n",
    "\n",
    "    rownum = 0\n",
    "    reader = csv.reader(trainingFile)\n",
    "    for row in reader:\n",
    "        # Save header row.\n",
    "        if rownum == 0:\n",
    "            header = row\n",
    "        else:\n",
    "            features = row[:len(row) - 1 ]\n",
    "            trainingFeatures.append(np.array(features).astype('float32'))\n",
    "            trainingLabels.append(np.array([row[-1]]).astype('float32'))\n",
    "\n",
    "                \n",
    "        rownum += 1\n",
    "    \n",
    "    for i in range(len(trainingLabels)):\n",
    "        if trainingLabels[i] == np.array([1.0]).astype('float32'):\n",
    "            trainingLabels[i] = np.array([0.0,1.0]).astype('float32')\n",
    "        else:\n",
    "            trainingLabels[i] = np.array([1.0,0.0]).astype('float32')\n",
    "    \n",
    "    trainingFeatures = preprocessing.scale(np.array(trainingFeatures))\n",
    "    trainingFeatures = [np.array(x).astype('float32') for x in trainingFeatures.tolist()]\n",
    "    if splitforTesting:\n",
    "        testingFeatures = trainingFeatures[len(trainingFeatures) - 10000 : len(trainingFeatures)]\n",
    "        testingLabels = trainingLabels[len(trainingLabels) - 10000 : len(trainingLabels)]\n",
    "\n",
    "        trainingFeatures = trainingFeatures[0:len(trainingFeatures) - 10000]\n",
    "        trainingLabels = trainingLabels[0:len(trainingLabels) - 10000]\n",
    "        return trainingFeatures, trainingLabels, testingFeatures, testingLabels\n",
    "\n",
    "    else:\n",
    "        return trainingFeatures, trainingLabels\n",
    "\n",
    "trainingImages, trainingLabels, testImages, testLabels = readTraining(splitforTesting = True)\n",
    "# trainingLabels = [labelToArray(a) for a,b in TrainingSetList]\n",
    "# trainingImages = [np.ravel(b) for (a,b) in TrainingSetList]\n",
    "# testLabels = [labelToArray(a) for a,b in TestSetList]\n",
    "# testImages = [np.ravel(b) for a,b in TestSetList]\n",
    "len(trainingLabels)\n",
    "print trainingImages[0].shape\n",
    "print trainingLabels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from autograd import grad\n",
    "def error((weights, biases), inputvec, outputvec):\n",
    "    return LA.norm(outputvec - feedforward((weights, biases, inputvec)))\n",
    "errorgrad = grad(error)\n",
    "\n",
    "def feedforward((weights, biases, inputvecx)):\n",
    "    for layer, bias in izip(weights, biases):\n",
    "        inputvecx = np.tanh(inputvecx)\n",
    "        inputvecx = np.dot(inputvecx, layer) + bias\n",
    "    return inputvecx\n",
    "\n",
    "def foo(x):\n",
    "    if x > 0.5:\n",
    "        return 1.0\n",
    "    return 0.0\n",
    "relu = np.vectorize(lambda x: x * (x> 0))\n",
    "binarize = np.vectorize(foo)\n",
    "        \n",
    "\n",
    "class classicneuralnet:\n",
    "    def __init__(self, inputsize, hiddenlayersizes, outputsize):\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.hiddenlayers = len(hiddenlayersizes)\n",
    "        self.totalsize = 0\n",
    "        \n",
    "        prevsize = inputsize\n",
    "        hiddenlayersizes.append(outputsize)\n",
    "        \n",
    "        for size in hiddenlayersizes:\n",
    "            self.weights.append(0.05 * np.random.random((prevsize,size)) - 0.05) # used to be prevsize + 1 with no biases\n",
    "            self.biases.append(0.1* np.random.random((1, size)))\n",
    "            self.totalsize += (prevsize + 1) * size\n",
    "            prevsize = size\n",
    "               \n",
    "    def feedforward(self, weights, biases, inputvec):\n",
    "        for layer, bias in izip(weights, biases):\n",
    "            inputvec = np.tanh(inputvec)\n",
    "            inputvec = np.dot(inputvec, layer) + bias\n",
    "        return inputvec\n",
    "    \n",
    "    def test(self, inputs, outputs):\n",
    "        errors = [outp * np.log(feedforward((self.weights, self.biases, inp))) for inp,outp in izip(inputs,outputs)]\n",
    "        return sum(errors)/len(inputs) * 100.0\n",
    "        \n",
    "        \n",
    "    \n",
    "    def train(self, inputlist, outputlist, alpha, batchsize, epochs, testinputlist = [], testoutputlist = [], verbose = False):\n",
    "        inlen = len(inputlist)\n",
    "        outlen = len(outputlist)\n",
    "        global error_grad\n",
    "        if inlen != outlen:\n",
    "            Exception(\"number of input vectors (\"+str(inlen)+\") not equal not number of ouptut vectors (\"+str(outlen)+\")\")\n",
    "            \n",
    "        if alpha == 0.0:\n",
    "            raise(\"why is alpha zero?\")\n",
    "            \n",
    "        if type(batchsize) != int:\n",
    "            raise(\"Why is batchsize not an int?\")\n",
    "        \n",
    "        if batchsize == 0 or batchsize > inlen:\n",
    "            raise(\"batchsize of \"+str(batchsize)+\"is not allowed. Note than inputveclist has length \"+str(inlen))\n",
    "            \n",
    "        #just some error checks\n",
    "        \n",
    "        randindexlist = range(inlen)\n",
    "        start = time.time()\n",
    "        avgpercenttesterror = \"No test set\"\n",
    "        avgpercenttesterrorlist = []\n",
    "        \n",
    "        #using stochastic gradient descent training method\n",
    "        for epoch in xrange(epochs):\n",
    "            #random.shuffle(randindexlist)\n",
    "            #for batch in range(inlen/batchsize):\n",
    "            \n",
    "#                 low = batch * batchsize\n",
    "#                 upper = (batch + 1) * batchsize\n",
    "#                 if upper > inlen: upper = inlen \n",
    "                \n",
    "#                 total_Egradweights = None\n",
    "#                 total_Egradbiases = None\n",
    "                \n",
    "#                 for i in randindexlist[low:upper]:\n",
    "            for inp,outp in izip(inputlist,outputlist):\n",
    "                Egradweights, Egradbiases = errorgrad((self.weights, self.biases),\n",
    "                                                                            inp, outp) #formerly used indexes from randindexlist\n",
    "#                     if total_Egradweights:\n",
    "#                         total_Egradweights = [x + y for x,y in izip(Egradweights,total_Egradweights)]\n",
    "#                         total_Egradbiases = [x + y for x,y in izip(Egradbiases,total_Egradbiases)]\n",
    "#                     else:\n",
    "#                         total_Egradweights = Egradweights\n",
    "#                         total_Egradbiases = Egradbiases\n",
    "                \n",
    "#                 total_Egradweights = [x / (batchsize * 1.0) for x in total_Egradweights]\n",
    "#                 total_Egradbiases = [x / (batchsize * 1.0) for x in total_Egradbiases]\n",
    "                \n",
    "#                 self.weights = [curr-grad*alpha for curr, grad in izip(self.weights, total_Egradweights)]\n",
    "#                 self.biases = [curr-grad*alpha for curr, grad in izip(self.biases, total_Egradbiases)]\n",
    "                self.weights = [curr-grad*alpha for curr, grad in izip(self.weights, Egradweights)]\n",
    "                self.biases = [curr-grad*alpha for curr, grad in izip(self.biases, Egradbiases)]\n",
    "            \n",
    "            if len(testinputlist) == len(testoutputlist) and len(testinputlist) != 0:\n",
    "                avgpercenttesterror = self.test(testinputlist, testoutputlist)\n",
    "                avgpercenttesterrorlist.append(avgpercenttesterror)\n",
    "            else:\n",
    "                print \"bad test set\"\n",
    "            \n",
    "            elapsed = time.time() - start\n",
    "            start = time.time()\n",
    "            if verbose:\n",
    "                print \"epoch: \" + str(epoch) + \"\\t percenterror: \" + str(avgpercenttesterror) + \"% \\t time elapsed this epoch: \" + str(elapsed) + \"s\"\n",
    "            \n",
    "        return (self.weights, self.biases, avgpercenttesterror, avgpercenttesterrorlist)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = classicneuralnet(21,[200,200], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\t percenterror: [[-46.15840547 -26.14615487]]% \t time elapsed this epoch: 289.859450102s\n",
      "epoch: 1\t percenterror: [[         nan -26.24315418]]% \t time elapsed this epoch: 348.201826096s\n",
      "epoch: 2\t percenterror: [[ nan  nan]]% \t time elapsed this epoch: 550.997834921s"
     ]
    }
   ],
   "source": [
    "test.train(trainingImages, trainingLabels, 0.001, 1, 25, testImages, testLabels, verbose = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainingImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nist = mnist.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nist.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.feedforward(test.weights,test.biases, np.array([0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.dot(np.array([1,1]), test.weights[0]) + test.biases[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myerror_grad = grad(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myerror_grad((test.weights, test.biases), np.array([1.0,0.0]), np.array([1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LA.norm(np.array([1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yodle = np.array([1,2])\n",
    "np.append(yodle, np.array([3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yodle + np.array([0,0,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.tanh(x)\n",
    "mygradient = grad(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = np.linspace(-7,7,100)\n",
    "plt.plot(x, map(f, x),x, map(mygradient, x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[[66.79, 36.666, 89.798, 84.6, 89.798, 88.644, 26.052, 36.658, 90.064, 89.798], [78.746, 26.198, 26.45, 55.928, 32.276, 31.29, 89.65, 28.562, 88.644, 28.218], [23.29, 26.948, 80.938, 88.644, 88.644, 89.798, 88.644, 89.65, 89.65, 23.044], [45.28, 20.102, 37.0, 33.524, 38.97, 30.598, 36.538, 88.644, 34.618, 36.778], [47.61, 19.204, 22.58, 16.552, 47.248, 32.586, 13.58, 53.264, 71.46, 56.824]]\n",
      "first generation [66.79, 36.666, 89.798, 84.6, 89.798, 88.644, 26.052, 36.658, 90.064, 89.798]\n",
      "fifth generation [47.61, 19.204, 22.58, 16.552, 47.248, 32.586, 13.58, 53.264, 71.46, 56.824]\n",
      "[[66.79, 36.666, 89.798, 84.6, 89.798, 88.644, 26.052, 36.658, 90.064, 89.798], [78.746, 26.198, 26.45, 55.928, 32.276, 31.29, 89.65, 28.562, 88.644, 28.218], [23.29, 26.948, 80.938, 88.644, 88.644, 89.798, 88.644, 89.65, 89.65, 23.044], [45.28, 20.102, 37.0, 33.524, 38.97, 30.598, 36.538, 88.644, 34.618, 36.778], [47.61, 19.204, 22.58, 16.552, 47.248, 32.586, 13.58, 53.264, 71.46, 56.824]]\n",
      "66.79\n",
      "36.666\n",
      "89.798\n",
      "84.6\n",
      "89.798\n",
      "88.644\n",
      "26.052\n",
      "36.658\n",
      "90.064\n",
      "89.798\n",
      "\n",
      "78.746\n",
      "26.198\n",
      "26.45\n",
      "55.928\n",
      "32.276\n",
      "31.29\n",
      "89.65\n",
      "28.562\n",
      "88.644\n",
      "28.218\n",
      "\n",
      "23.29\n",
      "26.948\n",
      "80.938\n",
      "88.644\n",
      "88.644\n",
      "89.798\n",
      "88.644\n",
      "89.65\n",
      "89.65\n",
      "23.044\n",
      "\n",
      "45.28\n",
      "20.102\n",
      "37.0\n",
      "33.524\n",
      "38.97\n",
      "30.598\n",
      "36.538\n",
      "88.644\n",
      "34.618\n",
      "36.778\n",
      "\n",
      "47.61\n",
      "19.204\n",
      "22.58\n",
      "16.552\n",
      "47.248\n",
      "32.586\n",
      "13.58\n",
      "53.264\n",
      "71.46\n",
      "56.824\n",
      "\n",
      "[26.052, 26.198, 23.044, 20.102, 13.58]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "prefix = \"unboxedIndividualReluV4\"\n",
    "directory = \"/home/helios/Drive/Skynet\"\n",
    "genSize = 10\n",
    "\n",
    "fnames = [f for f in os.listdir(directory) if prefix in f]\n",
    "\n",
    "timesandErrors = []\n",
    "for fname in fnames:\n",
    "    with open(fname) as f:\n",
    "        timesandErrors.append((os.path.getctime(fname), json.loads(f.readline())))\n",
    "\n",
    "timesandErrors.sort(key=lambda x: x[0])\n",
    "timesandErrors = map (lambda x : x[1], timesandErrors)\n",
    "\n",
    "chunked = [timesandErrors[i:i+genSize] for i in xrange(0,len(timesandErrors),genSize)]\n",
    "\n",
    "chunked = chunked[0:len(chunked)-1]\n",
    "print len(chunked)\n",
    "minned = map (lambda l: map(min,l), chunked)\n",
    "print minned\n",
    "\n",
    "print \"first generation \" + str(minned[0])\n",
    "print \"fifth generation \" + str(minned[-1])\n",
    "print minned\n",
    "averages = map (lambda ls: sum(ls)/genSize, minned)\n",
    "returned = map(lambda l: str('\\n'.join(map(str, l))), minned)\n",
    "for ret in returned:\n",
    "    print ret\n",
    "    print\n",
    "bestIndividuals = map (lambda ls: min(map(lambda l: min(l), ls)), chunked)\n",
    "print bestIndividuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "x,y=numpy.ogrid[-2:1:10000j,-1.5:1.5:10000j]\n",
    "\n",
    "print('')\n",
    "print('Grid set')\n",
    "print('')\n",
    "\n",
    "c=x + 1j*y\n",
    "z=0\n",
    "\n",
    "for g in range(20):\n",
    "        print('Iteration number: ',g)\n",
    "        z=z**2 + c\n",
    "\n",
    "threshold = 2\n",
    "mask=numpy.abs(z) < threshold\n",
    "\n",
    "print('')\n",
    "print('Plotting using imshow()')\n",
    "plt.imshow(mask.T,extent=[-2,1,-1.5,1.5])\n",
    "\n",
    "print('')\n",
    "print('plotting done')\n",
    "print('')\n",
    "\n",
    "plt.gray()\n",
    "\n",
    "print('')\n",
    "print('Preparing to render')\n",
    "print('')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "range(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Out[55][0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[1,2]-[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(xrange(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(3) == int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[1,2,3] + None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y += 1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if None:\n",
    "    print \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shuffle = [1,2,3,4] \n",
    "random.shuffle(shuffle)\n",
    "shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[1,2,3][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.random((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[1,2] + [3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[1,2] + None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hi = [1,2,3]\n",
    "hi /= 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "3/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T.vector(numpy.array([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  3.,  6.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "x = T.fvector()\n",
    "y = T.fmatrix()\n",
    "z = T.dot(x, y)\n",
    "f = theano.function([x,y],z)\n",
    "f(np.array([1,2]).astype(theano.config.floatX), np.array([range(3), range(3)]).astype(theano.config.floatX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  5.  3.  5.]\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "import time\n",
    "inds = T.imatrix('inds')\n",
    "x = T.fvector('x')\n",
    "chosen = x.take(inds).sum(axis = 1)\n",
    "chosen = T.concatenate([chosen, chosen])\n",
    "theanof = theano.function([inds,x], chosen)\n",
    "print theanof( np.array([[1,2],[2,3]]).astype('int32'), np.arange(31).astype(theano.config.floatX))\n",
    "# y, _ = theano.map(fn = lambda i : x[i], sequences = inds)\n",
    "# scanf = theano.function([inds,x], y)\n",
    "\n",
    "# listinds = range(10000000)\n",
    "# npinds = np.array(listinds).astype('int32')\n",
    "# npx = np.array(listinds).astype(theano.config.floatX)\n",
    "# # print type(npinds)\n",
    "# # print type(npx)\n",
    "# # mylist = np.array(range(31))\n",
    "# # print mylist\n",
    "# # print np.choose(np.array([1,2]), mylist)\n",
    "# testStart = time.time()\n",
    "# x = theanof(npinds, npx)\n",
    "# print \"choose did it in: \" + str(time.time() - testStart)\n",
    "# # testStart = time.time()\n",
    "# # x = scanf(npinds, npx)\n",
    "# # print \"map did it in: \" + str(time.time() - testStart)\n",
    "# testStart = time.time()\n",
    "# x = npx.take(npinds)\n",
    "# print \"python did in in: \" + str(time.time() - testStart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 'hello']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,\"hello\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from theano import tensor as T\n",
    "x = T.fvector('x')\n",
    "inds = T.ivector()\n",
    "y = T.choose(inds,x)\n",
    "f = theano.function([x,inds], y)\n",
    "f(np.array(range(31)).astype(theano.config.floatX), np.array([1]).astype('int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(2.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 of 1] Compiling Main             ( fractalUnboxedReluV2.hs, fractalUnboxedReluV2.o )\n",
      "Linking fractalUnboxedReluV2 ...\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cd ~/Drive/Skynet\n",
    "ghc -O2 -threaded -optc-O3 -optc-ffast-math -rtsopts -fexcess-precision -fprof-auto -fbreak-on-exception fractalUnboxedReluV2.hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 970 (CNMeM is disabled, cuDNN not available)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/preprocessing/data.py:167: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data into RAM...\n",
      "reformatting data...\n",
      "10000\n",
      "86320\n",
      "[ 1.55478084 -0.35435715 -1.53061199 -0.94231004  0.37014699 -0.23755288\n",
      " -1.1931684   1.4748404  -1.39032066 -1.32913303 -0.83353394 -1.41917324\n",
      "  1.07797825 -1.02009034  0.6895715   1.13847876 -0.27244335 -0.70867389\n",
      "  1.54909635  0.38860792 -0.30387601]\n",
      "[ 0.  1.]\n",
      "data reformatting complete. Beginning evolution. Training is 86320examples, testing 10000\n",
      "nnetEvaluator testingims length: 10000\n",
      "evaluating\n",
      "running initial singleGenConsolidate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python2.7/site-packages/sklearn/preprocessing/data.py:184: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "starting to loop\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "looped\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate"
     ]
    }
   ],
   "source": [
    "import fulcrum\n",
    "fulcrum.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helios   28940 99.9 27.6 4825216 4479628 tty1  Rl   12:42  21:03 /home/helios/Drive/Skynet/fractalUnboxedReluV2\n",
      "helios   29037  0.0  0.0 112648   944 tty1     S    13:04   0:00 grep fractal\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ps -aux | grep fractal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "kill 26985"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"numerai_training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature1\n",
      "0.000000      1\n",
      "0.000031    102\n",
      "0.000242     93\n",
      "0.002356     96\n",
      "0.002505     96\n",
      "0.002936     87\n",
      "0.004300     88\n",
      "0.005682     91\n",
      "0.007780     98\n",
      "0.007780    102\n",
      "0.007780     88\n",
      "0.009855     98\n",
      "0.010086     94\n",
      "0.010706    103\n",
      "0.010725     99\n",
      "0.012213     92\n",
      "0.012652    111\n",
      "0.012678     88\n",
      "0.015628    105\n",
      "0.015687     89\n",
      "0.015937     85\n",
      "0.017520     95\n",
      "0.017528    101\n",
      "0.019466     95\n",
      "0.019469     87\n",
      "0.021334     98\n",
      "0.021581    107\n",
      "0.021675     97\n",
      "0.024439     98\n",
      "0.025309     89\n",
      "           ... \n",
      "0.966091     97\n",
      "0.966925     91\n",
      "0.967753     96\n",
      "0.967971    106\n",
      "0.968112     90\n",
      "0.970254     85\n",
      "0.970636     87\n",
      "0.972762     93\n",
      "0.973878     94\n",
      "0.974237     97\n",
      "0.974831     89\n",
      "0.975005    101\n",
      "0.975760     93\n",
      "0.975761     98\n",
      "0.975892    102\n",
      "0.977119    105\n",
      "0.978595     93\n",
      "0.981748     87\n",
      "0.982411     98\n",
      "0.983594     95\n",
      "0.983627    104\n",
      "0.985582     93\n",
      "0.985625     94\n",
      "0.989442     97\n",
      "0.989499     93\n",
      "0.991919    102\n",
      "0.997193     92\n",
      "0.997223     94\n",
      "0.997515    102\n",
      "1.000000     95\n",
      "Name: feature1, dtype: int64\n",
      "feature2\n",
      "0.000000e+00      1\n",
      "4.921649e-07     90\n",
      "5.382284e-04    101\n",
      "1.922934e-03     96\n",
      "4.395847e-03     97\n",
      "4.931384e-03     98\n",
      "6.233714e-03     97\n",
      "6.793336e-03     98\n",
      "7.065811e-03    108\n",
      "7.073947e-03     90\n",
      "7.416325e-03     98\n",
      "8.121382e-03    107\n",
      "8.593137e-03     99\n",
      "8.850632e-03     95\n",
      "1.056004e-02     97\n",
      "1.063291e-02     95\n",
      "1.066595e-02    100\n",
      "1.293608e-02     93\n",
      "1.413142e-02    102\n",
      "1.429745e-02    109\n",
      "1.507721e-02    106\n",
      "1.620410e-02    102\n",
      "1.625370e-02     92\n",
      "1.634436e-02     97\n",
      "1.642325e-02     99\n",
      "1.814392e-02     92\n",
      "1.814586e-02     99\n",
      "2.037530e-02    102\n",
      "2.061345e-02    105\n",
      "2.313349e-02     90\n",
      "               ... \n",
      "9.757847e-01    103\n",
      "9.768597e-01     95\n",
      "9.777202e-01     97\n",
      "9.777298e-01     99\n",
      "9.790765e-01    100\n",
      "9.800056e-01    105\n",
      "9.813686e-01     99\n",
      "9.817884e-01     95\n",
      "9.837487e-01     92\n",
      "9.837632e-01    107\n",
      "9.837633e-01    102\n",
      "9.839719e-01     91\n",
      "9.842727e-01     94\n",
      "9.842952e-01     95\n",
      "9.846304e-01    109\n",
      "9.866648e-01     96\n",
      "9.870253e-01     92\n",
      "9.877979e-01     96\n",
      "9.878024e-01     95\n",
      "9.878030e-01     92\n",
      "9.881421e-01    100\n",
      "9.901255e-01     93\n",
      "9.903211e-01     91\n",
      "9.903431e-01     97\n",
      "9.918277e-01     99\n",
      "9.918780e-01    103\n",
      "9.921027e-01     93\n",
      "9.935126e-01    103\n",
      "9.992200e-01     96\n",
      "1.000000e+00     93\n",
      "Name: feature2, dtype: int64\n",
      "feature3\n",
      "0.000191    100\n",
      "0.003110     98\n",
      "0.004514    105\n",
      "0.004819     99\n",
      "0.004819     94\n",
      "0.004849     98\n",
      "0.004849    101\n",
      "0.006505    100\n",
      "0.009587    101\n",
      "0.009758    108\n",
      "0.009783    101\n",
      "0.010462     93\n",
      "0.011590    102\n",
      "0.011590     92\n",
      "0.012716     92\n",
      "0.015466     99\n",
      "0.015511    103\n",
      "0.015527    101\n",
      "0.015983     87\n",
      "0.019206     87\n",
      "0.019380     95\n",
      "0.019431     95\n",
      "0.020117     98\n",
      "0.020655    100\n",
      "0.021358     98\n",
      "0.021589    106\n",
      "0.024384     92\n",
      "0.027383     93\n",
      "0.027965    103\n",
      "0.030934     94\n",
      "           ... \n",
      "0.975685     99\n",
      "0.975970     99\n",
      "0.976868     98\n",
      "0.976910     97\n",
      "0.977350     81\n",
      "0.977352     98\n",
      "0.977867    100\n",
      "0.979631     95\n",
      "0.981396     90\n",
      "0.982669     94\n",
      "0.982669     94\n",
      "0.984829    101\n",
      "0.984847    108\n",
      "0.984862     99\n",
      "0.986546    106\n",
      "0.986662    106\n",
      "0.986668    104\n",
      "0.990510    102\n",
      "0.990604    100\n",
      "0.992313    103\n",
      "0.993223     96\n",
      "0.994277     99\n",
      "0.994285    101\n",
      "0.995519     93\n",
      "0.997954     94\n",
      "0.998524     96\n",
      "0.998762     94\n",
      "0.999078     99\n",
      "0.999240     96\n",
      "1.000000    100\n",
      "Name: feature3, dtype: int64\n",
      "feature4\n",
      "0.000000      1\n",
      "0.000926    102\n",
      "0.000961    108\n",
      "0.000971     88\n",
      "0.002032     97\n",
      "0.002107     99\n",
      "0.003476     84\n",
      "0.003559     99\n",
      "0.003560    103\n",
      "0.004366     95\n",
      "0.004629     94\n",
      "0.004668     94\n",
      "0.004778     95\n",
      "0.005022     96\n",
      "0.007689     98\n",
      "0.008265    100\n",
      "0.008273     92\n",
      "0.008531     97\n",
      "0.010593    104\n",
      "0.012443     94\n",
      "0.012449     96\n",
      "0.012879    104\n",
      "0.013384     99\n",
      "0.014538    104\n",
      "0.014541     98\n",
      "0.016659    101\n",
      "0.016756     95\n",
      "0.017281    101\n",
      "0.020664    102\n",
      "0.021654    106\n",
      "           ... \n",
      "0.966023    103\n",
      "0.967595     90\n",
      "0.969746    107\n",
      "0.969794     99\n",
      "0.970431     95\n",
      "0.973867     93\n",
      "0.973877     97\n",
      "0.978078     97\n",
      "0.978174     96\n",
      "0.982686     94\n",
      "0.983014    109\n",
      "0.984493     98\n",
      "0.984867     99\n",
      "0.984907    105\n",
      "0.986408     96\n",
      "0.986485     95\n",
      "0.987023     98\n",
      "0.987758     98\n",
      "0.988131     96\n",
      "0.990656     91\n",
      "0.990791     99\n",
      "0.994812    105\n",
      "0.994835    106\n",
      "0.996055    109\n",
      "0.996475    102\n",
      "0.998961     96\n",
      "0.998967     87\n",
      "0.999216     95\n",
      "0.999340    100\n",
      "1.000000     93\n",
      "Name: feature4, dtype: int64\n",
      "feature5\n",
      "0.000810     91\n",
      "0.001605     91\n",
      "0.001626     98\n",
      "0.001642    111\n",
      "0.004097    103\n",
      "0.005191    101\n",
      "0.005259    101\n",
      "0.005271    102\n",
      "0.005970     93\n",
      "0.008028     90\n",
      "0.008343     93\n",
      "0.008620     95\n",
      "0.009256     96\n",
      "0.009977    106\n",
      "0.009977     96\n",
      "0.010258    101\n",
      "0.010273     97\n",
      "0.011368     90\n",
      "0.012177    100\n",
      "0.012599    106\n",
      "0.012633     96\n",
      "0.012640     88\n",
      "0.014182     95\n",
      "0.014237    105\n",
      "0.015243     89\n",
      "0.015313    101\n",
      "0.015369     99\n",
      "0.016279     94\n",
      "0.016279    101\n",
      "0.016399     88\n",
      "           ... \n",
      "0.966087    102\n",
      "0.966693    100\n",
      "0.969675     96\n",
      "0.970623     93\n",
      "0.974646    102\n",
      "0.976268     97\n",
      "0.976312     99\n",
      "0.976316     96\n",
      "0.976772     99\n",
      "0.977374    100\n",
      "0.977383     91\n",
      "0.978288    103\n",
      "0.978632     97\n",
      "0.978999     98\n",
      "0.979194     92\n",
      "0.980892    106\n",
      "0.982793     93\n",
      "0.983168     99\n",
      "0.986919    101\n",
      "0.986970     92\n",
      "0.991848     89\n",
      "0.992086     95\n",
      "0.994171    101\n",
      "0.995265     96\n",
      "0.995439     97\n",
      "0.999307     92\n",
      "0.999419    100\n",
      "0.999423     91\n",
      "0.999590    101\n",
      "1.000000     97\n",
      "Name: feature5, dtype: int64\n",
      "feature6\n",
      "0.000000      1\n",
      "0.001028     96\n",
      "0.004037     93\n",
      "0.005700     96\n",
      "0.006245    105\n",
      "0.008450     99\n",
      "0.011353    104\n",
      "0.012144     95\n",
      "0.012434     92\n",
      "0.012438    100\n",
      "0.013457    105\n",
      "0.013521     98\n",
      "0.013671     96\n",
      "0.013675     97\n",
      "0.015384     91\n",
      "0.015646     92\n",
      "0.017390    101\n",
      "0.017544     90\n",
      "0.018043     94\n",
      "0.020535     97\n",
      "0.021257    102\n",
      "0.021266     97\n",
      "0.023381    100\n",
      "0.027195    101\n",
      "0.027569     91\n",
      "0.029171     97\n",
      "0.029493    100\n",
      "0.030675     96\n",
      "0.031109     98\n",
      "0.031147    106\n",
      "           ... \n",
      "0.966516     92\n",
      "0.972330     97\n",
      "0.973355     97\n",
      "0.973993    103\n",
      "0.974509    101\n",
      "0.975053     96\n",
      "0.976219     96\n",
      "0.976258     94\n",
      "0.977107     97\n",
      "0.978100    109\n",
      "0.978145     86\n",
      "0.978165    102\n",
      "0.980244    102\n",
      "0.980467     92\n",
      "0.980906    100\n",
      "0.981430     96\n",
      "0.982042     90\n",
      "0.982043    103\n",
      "0.985189     93\n",
      "0.985993     96\n",
      "0.985995     96\n",
      "0.987924    105\n",
      "0.987924     95\n",
      "0.988274     98\n",
      "0.988611     94\n",
      "0.989308    100\n",
      "0.994682    102\n",
      "0.997230    108\n",
      "0.999782    101\n",
      "1.000000     99\n",
      "Name: feature6, dtype: int64\n",
      "feature7\n",
      "0.000063     96\n",
      "0.000090    103\n",
      "0.006304    101\n",
      "0.008091    102\n",
      "0.008127     95\n",
      "0.009824     99\n",
      "0.010128     89\n",
      "0.010137    106\n",
      "0.012157     95\n",
      "0.012159     95\n",
      "0.012305     93\n",
      "0.016265     98\n",
      "0.016748    104\n",
      "0.016785    105\n",
      "0.016808     95\n",
      "0.017546     99\n",
      "0.018473    100\n",
      "0.020275    106\n",
      "0.020278    101\n",
      "0.021194    102\n",
      "0.021970     95\n",
      "0.024055    105\n",
      "0.024759    105\n",
      "0.025003    109\n",
      "0.026804    102\n",
      "0.028989     98\n",
      "0.029409     90\n",
      "0.029418     89\n",
      "0.032212     95\n",
      "0.032952     96\n",
      "           ... \n",
      "0.966882    107\n",
      "0.967907    103\n",
      "0.968889     95\n",
      "0.971339    101\n",
      "0.974550     94\n",
      "0.974709     98\n",
      "0.976823     93\n",
      "0.978774     92\n",
      "0.979122     95\n",
      "0.979151    103\n",
      "0.979876     99\n",
      "0.982298     97\n",
      "0.986213     91\n",
      "0.987724    111\n",
      "0.988321     96\n",
      "0.990794     90\n",
      "0.991436    102\n",
      "0.991788    107\n",
      "0.991788     97\n",
      "0.991891     84\n",
      "0.992045     97\n",
      "0.992902     98\n",
      "0.992965     95\n",
      "0.993760     90\n",
      "0.995969     94\n",
      "0.998012     96\n",
      "0.998941    101\n",
      "0.999126    101\n",
      "0.999410    102\n",
      "1.000000     97\n",
      "Name: feature7, dtype: int64\n",
      "feature8\n",
      "0.000000      1\n",
      "0.000625    105\n",
      "0.000841    100\n",
      "0.000946     85\n",
      "0.001633     97\n",
      "0.002332     95\n",
      "0.004058    102\n",
      "0.004199     98\n",
      "0.008116    104\n",
      "0.008123     97\n",
      "0.009161     93\n",
      "0.009161     98\n",
      "0.009172     98\n",
      "0.010285     96\n",
      "0.010467    100\n",
      "0.012520     96\n",
      "0.012991    104\n",
      "0.014609     92\n",
      "0.016547    105\n",
      "0.016571     98\n",
      "0.018664     90\n",
      "0.018673    102\n",
      "0.018844     94\n",
      "0.019516    100\n",
      "0.022605     96\n",
      "0.024984     85\n",
      "0.024984     91\n",
      "0.025331     94\n",
      "0.029252    103\n",
      "0.030041     98\n",
      "           ... \n",
      "0.970904     90\n",
      "0.970933    103\n",
      "0.970953    107\n",
      "0.971193     87\n",
      "0.971197     98\n",
      "0.971736     92\n",
      "0.972668     94\n",
      "0.973868     86\n",
      "0.978577     93\n",
      "0.978610     99\n",
      "0.979060    100\n",
      "0.979335     97\n",
      "0.980080    103\n",
      "0.982676     99\n",
      "0.985152     86\n",
      "0.987095     89\n",
      "0.987259     96\n",
      "0.987583    101\n",
      "0.987749     97\n",
      "0.991236     91\n",
      "0.991236     99\n",
      "0.995629     92\n",
      "0.996216    103\n",
      "0.996882     97\n",
      "0.997723    102\n",
      "0.998316     97\n",
      "0.999286     96\n",
      "0.999718    101\n",
      "0.999912     92\n",
      "1.000000    102\n",
      "Name: feature8, dtype: int64\n",
      "feature9\n",
      "0.000006    109\n",
      "0.000968     95\n",
      "0.000973     95\n",
      "0.001837    101\n",
      "0.003986    100\n",
      "0.004307     94\n",
      "0.007735     93\n",
      "0.007735     93\n",
      "0.007782    101\n",
      "0.008081     97\n",
      "0.009875     93\n",
      "0.010092    101\n",
      "0.012922    105\n",
      "0.015040    101\n",
      "0.015472    104\n",
      "0.015474     96\n",
      "0.015497    100\n",
      "0.015527    104\n",
      "0.015966    101\n",
      "0.018181     96\n",
      "0.019919    102\n",
      "0.020322     97\n",
      "0.020454     93\n",
      "0.021480     96\n",
      "0.021757     94\n",
      "0.021767     97\n",
      "0.023243    102\n",
      "0.024075     97\n",
      "0.024375     94\n",
      "0.024608    102\n",
      "           ... \n",
      "0.974765     95\n",
      "0.974773     99\n",
      "0.975012     99\n",
      "0.975863     93\n",
      "0.976554    101\n",
      "0.976926    101\n",
      "0.978811    100\n",
      "0.979918     98\n",
      "0.980619    102\n",
      "0.980687     96\n",
      "0.983234     89\n",
      "0.983517     98\n",
      "0.983540     97\n",
      "0.985723    102\n",
      "0.986435    106\n",
      "0.988539     95\n",
      "0.989560    103\n",
      "0.990448     89\n",
      "0.990742     98\n",
      "0.990794     99\n",
      "0.991325     97\n",
      "0.991560    107\n",
      "0.994104     95\n",
      "0.996779    108\n",
      "0.997974    103\n",
      "0.997977     96\n",
      "0.998303     98\n",
      "0.999676     96\n",
      "0.999954     94\n",
      "1.000000     95\n",
      "Name: feature9, dtype: int64\n",
      "feature10\n",
      "0.000034    106\n",
      "0.001878    104\n",
      "0.005187     96\n",
      "0.006321    100\n",
      "0.006385    105\n",
      "0.008380    101\n",
      "0.008407    106\n",
      "0.008414     96\n",
      "0.008440    106\n",
      "0.008899     97\n",
      "0.008902     98\n",
      "0.011434    102\n",
      "0.011830    102\n",
      "0.012676    106\n",
      "0.013104     99\n",
      "0.013888     97\n",
      "0.015027     94\n",
      "0.015756    104\n",
      "0.016770    109\n",
      "0.016775    108\n",
      "0.016807    101\n",
      "0.017321    101\n",
      "0.017575    103\n",
      "0.017904     99\n",
      "0.020984    101\n",
      "0.021179    102\n",
      "0.022024    100\n",
      "0.022030     95\n",
      "0.025166    104\n",
      "0.025167    108\n",
      "           ... \n",
      "0.961330    102\n",
      "0.961346     94\n",
      "0.965690     95\n",
      "0.965923     90\n",
      "0.966443     97\n",
      "0.966571     95\n",
      "0.966631     94\n",
      "0.967448     99\n",
      "0.969746     99\n",
      "0.969770     96\n",
      "0.970245    104\n",
      "0.971783     94\n",
      "0.971813     94\n",
      "0.971817     96\n",
      "0.975627     87\n",
      "0.976012     93\n",
      "0.976014     95\n",
      "0.978828     96\n",
      "0.981335    105\n",
      "0.982482     94\n",
      "0.983598    105\n",
      "0.984531    100\n",
      "0.984813     94\n",
      "0.990995    100\n",
      "0.991368    105\n",
      "0.991857     95\n",
      "0.994508    107\n",
      "0.999175     96\n",
      "0.999279     95\n",
      "1.000000     99\n",
      "Name: feature10, dtype: int64\n",
      "feature11\n",
      "0.000000      1\n",
      "0.000041    105\n",
      "0.000376     97\n",
      "0.000751    108\n",
      "0.002001    109\n",
      "0.002006    112\n",
      "0.002056    110\n",
      "0.004068    107\n",
      "0.004127    105\n",
      "0.008022    104\n",
      "0.008064    102\n",
      "0.008078    109\n",
      "0.009479    110\n",
      "0.010155    104\n",
      "0.010183    113\n",
      "0.010199     98\n",
      "0.012095    110\n",
      "0.012189    107\n",
      "0.012369    108\n",
      "0.012568    101\n",
      "0.012569    102\n",
      "0.013086    106\n",
      "0.013892    115\n",
      "0.016123    106\n",
      "0.016659    106\n",
      "0.017100    105\n",
      "0.017103    101\n",
      "0.020192    108\n",
      "0.020243    108\n",
      "0.020255    111\n",
      "           ... \n",
      "0.973229     96\n",
      "0.974201     97\n",
      "0.974220     91\n",
      "0.977624    100\n",
      "0.978497     96\n",
      "0.979205    110\n",
      "0.979205     93\n",
      "0.980249     91\n",
      "0.980517    100\n",
      "0.982224     96\n",
      "0.982224     97\n",
      "0.982754    107\n",
      "0.982843     83\n",
      "0.985012    101\n",
      "0.987180     95\n",
      "0.990277     87\n",
      "0.990289     97\n",
      "0.990402     94\n",
      "0.990809    106\n",
      "0.990812    102\n",
      "0.991308    107\n",
      "0.992256     91\n",
      "0.994316    103\n",
      "0.994323    105\n",
      "0.998386     95\n",
      "0.998410     98\n",
      "0.998714    108\n",
      "0.999334    100\n",
      "0.999343     92\n",
      "1.000000     95\n",
      "Name: feature11, dtype: int64\n",
      "feature12\n",
      "0.000000      1\n",
      "0.000070    101\n",
      "0.000194     90\n",
      "0.000716    100\n",
      "0.002197     98\n",
      "0.003788     99\n",
      "0.004224    103\n",
      "0.004631    111\n",
      "0.007397     96\n",
      "0.007491    104\n",
      "0.007503    101\n",
      "0.009022     98\n",
      "0.009480     98\n",
      "0.009624     98\n",
      "0.012523    102\n",
      "0.015088     97\n",
      "0.015298    100\n",
      "0.015497    113\n",
      "0.016986    108\n",
      "0.016986    105\n",
      "0.017140    101\n",
      "0.017839     98\n",
      "0.017937     95\n",
      "0.017982     93\n",
      "0.018887     92\n",
      "0.018894     94\n",
      "0.019023    104\n",
      "0.019424    101\n",
      "0.020837     83\n",
      "0.020854     96\n",
      "           ... \n",
      "0.976288     97\n",
      "0.977193    100\n",
      "0.977743    102\n",
      "0.979312     91\n",
      "0.980009    102\n",
      "0.980018    105\n",
      "0.980019    105\n",
      "0.980223     98\n",
      "0.980705     96\n",
      "0.980969     94\n",
      "0.981903     94\n",
      "0.982332    104\n",
      "0.983589    100\n",
      "0.984120    101\n",
      "0.984666    100\n",
      "0.987585     86\n",
      "0.987587     88\n",
      "0.987723     98\n",
      "0.987934    103\n",
      "0.988527     96\n",
      "0.989606     95\n",
      "0.993083     92\n",
      "0.995182     95\n",
      "0.995182     81\n",
      "0.995286    103\n",
      "0.996133    103\n",
      "0.996133     91\n",
      "0.997629     96\n",
      "0.999152    104\n",
      "1.000000     95\n",
      "Name: feature12, dtype: int64\n",
      "feature13\n",
      "0.000035     98\n",
      "0.000644    108\n",
      "0.001932     94\n",
      "0.002041     97\n",
      "0.002042    101\n",
      "0.002850     97\n",
      "0.004107     99\n",
      "0.004107    101\n",
      "0.004259    102\n",
      "0.008482     86\n",
      "0.008500    111\n",
      "0.008504     92\n",
      "0.008756    106\n",
      "0.008756    103\n",
      "0.010259     91\n",
      "0.010872    107\n",
      "0.012406    100\n",
      "0.012714     97\n",
      "0.014421     95\n",
      "0.015697     97\n",
      "0.016506     90\n",
      "0.016511    102\n",
      "0.016577     97\n",
      "0.017371     92\n",
      "0.017550    105\n",
      "0.017855     86\n",
      "0.020392    101\n",
      "0.020884     90\n",
      "0.021679     97\n",
      "0.021792    105\n",
      "           ... \n",
      "0.968984     94\n",
      "0.969048     98\n",
      "0.969971     90\n",
      "0.969971    104\n",
      "0.971122     98\n",
      "0.971581    105\n",
      "0.975301     98\n",
      "0.975653    105\n",
      "0.975653    100\n",
      "0.976495    100\n",
      "0.979284    102\n",
      "0.979373     99\n",
      "0.981707    100\n",
      "0.981869     95\n",
      "0.984957     96\n",
      "0.986202     99\n",
      "0.986503    100\n",
      "0.986505    111\n",
      "0.991863    106\n",
      "0.992925     89\n",
      "0.993730    105\n",
      "0.993732     98\n",
      "0.996201    108\n",
      "0.996703    105\n",
      "0.997056    104\n",
      "0.997928     98\n",
      "0.998039     90\n",
      "0.999928     96\n",
      "0.999928    102\n",
      "1.000000    102\n",
      "Name: feature13, dtype: int64\n",
      "feature14\n",
      "0.000000      1\n",
      "0.000117     98\n",
      "0.000182    105\n",
      "0.000951    101\n",
      "0.000951     97\n",
      "0.002123    104\n",
      "0.003985     89\n",
      "0.004042     91\n",
      "0.004876     98\n",
      "0.004880    101\n",
      "0.007847     98\n",
      "0.007948     98\n",
      "0.008220     98\n",
      "0.009775    100\n",
      "0.009820    103\n",
      "0.010046     93\n",
      "0.010802     97\n",
      "0.011987     87\n",
      "0.015657     94\n",
      "0.015870     98\n",
      "0.016542     97\n",
      "0.016644    104\n",
      "0.016729     93\n",
      "0.017641     90\n",
      "0.017706     87\n",
      "0.018798     98\n",
      "0.019627     97\n",
      "0.019793    101\n",
      "0.030795     99\n",
      "0.031341     95\n",
      "           ... \n",
      "0.972836     84\n",
      "0.974152     93\n",
      "0.976317    111\n",
      "0.976388    101\n",
      "0.979657     79\n",
      "0.980308    108\n",
      "0.980344     99\n",
      "0.980355    110\n",
      "0.982254    107\n",
      "0.982725    102\n",
      "0.982726    107\n",
      "0.984230    101\n",
      "0.984260    100\n",
      "0.985481     87\n",
      "0.986162    102\n",
      "0.986185     86\n",
      "0.988992     96\n",
      "0.990060    102\n",
      "0.990657    102\n",
      "0.992060    106\n",
      "0.992078     99\n",
      "0.992151    100\n",
      "0.994016     98\n",
      "0.994057    108\n",
      "0.995958     96\n",
      "0.995960     94\n",
      "0.996122     97\n",
      "0.996199     95\n",
      "0.999161    104\n",
      "1.000000     97\n",
      "Name: feature14, dtype: int64\n",
      "feature15\n",
      "0.000000      1\n",
      "0.000006     88\n",
      "0.000184     96\n",
      "0.002398    101\n",
      "0.003440    102\n",
      "0.008932    101\n",
      "0.010602     91\n",
      "0.013963    103\n",
      "0.014767    102\n",
      "0.016120    104\n",
      "0.016143     93\n",
      "0.017771    105\n",
      "0.019894     91\n",
      "0.020824     99\n",
      "0.021667    104\n",
      "0.032586    104\n",
      "0.033164     93\n",
      "0.033411     90\n",
      "0.033723    109\n",
      "0.034445    105\n",
      "0.034514    103\n",
      "0.034515     98\n",
      "0.034849     96\n",
      "0.034975     96\n",
      "0.035270     89\n",
      "0.035270     95\n",
      "0.035328    100\n",
      "0.035581    103\n",
      "0.039408    102\n",
      "0.040312     97\n",
      "           ... \n",
      "0.967832     95\n",
      "0.968251    107\n",
      "0.968797    100\n",
      "0.968799    100\n",
      "0.968804     88\n",
      "0.971653    103\n",
      "0.972283     98\n",
      "0.973848     95\n",
      "0.973971    100\n",
      "0.975905     97\n",
      "0.976280    101\n",
      "0.976358    104\n",
      "0.976386     99\n",
      "0.979928     92\n",
      "0.979981     96\n",
      "0.981037    108\n",
      "0.984477     98\n",
      "0.984976    106\n",
      "0.985058    101\n",
      "0.985936     88\n",
      "0.985939    101\n",
      "0.989367    101\n",
      "0.989967     97\n",
      "0.989967    102\n",
      "0.991983     97\n",
      "0.991983    101\n",
      "0.992141    101\n",
      "0.995663    105\n",
      "0.997043    102\n",
      "1.000000     96\n",
      "Name: feature15, dtype: int64\n",
      "feature16\n",
      "0.000114     94\n",
      "0.000964     99\n",
      "0.001880     94\n",
      "0.001890     99\n",
      "0.006303    101\n",
      "0.007881    102\n",
      "0.007922     93\n",
      "0.007988     94\n",
      "0.008899    101\n",
      "0.008925     90\n",
      "0.009887    100\n",
      "0.009933     92\n",
      "0.010589     98\n",
      "0.011152    109\n",
      "0.011383     88\n",
      "0.011466     92\n",
      "0.011734     97\n",
      "0.011899     96\n",
      "0.012004     99\n",
      "0.013704     93\n",
      "0.014804    104\n",
      "0.015870    106\n",
      "0.015873     88\n",
      "0.015873    106\n",
      "0.016183    103\n",
      "0.016885    104\n",
      "0.016899     91\n",
      "0.023747     92\n",
      "0.023919    103\n",
      "0.024544     96\n",
      "           ... \n",
      "0.976523     91\n",
      "0.977530     99\n",
      "0.977551     92\n",
      "0.977627    105\n",
      "0.978183     88\n",
      "0.979592    100\n",
      "0.980235     98\n",
      "0.980882     96\n",
      "0.981155    103\n",
      "0.981873    101\n",
      "0.983725    100\n",
      "0.983777     92\n",
      "0.983782    113\n",
      "0.984041    104\n",
      "0.984062     97\n",
      "0.987371    101\n",
      "0.987556     99\n",
      "0.988085     91\n",
      "0.988268     96\n",
      "0.991520     93\n",
      "0.991529    100\n",
      "0.991868     98\n",
      "0.992371    102\n",
      "0.993188    102\n",
      "0.993519     94\n",
      "0.993797    100\n",
      "0.995750    107\n",
      "0.995948     97\n",
      "0.999707     99\n",
      "1.000000     90\n",
      "Name: feature16, dtype: int64\n",
      "feature17\n",
      "0.000000      1\n",
      "0.000004    102\n",
      "0.000126     95\n",
      "0.000126     99\n",
      "0.000659     98\n",
      "0.003599     92\n",
      "0.004031     97\n",
      "0.004033    100\n",
      "0.006563    101\n",
      "0.007335     92\n",
      "0.007931    100\n",
      "0.008060    101\n",
      "0.008060     87\n",
      "0.008138     85\n",
      "0.008365     98\n",
      "0.008537     94\n",
      "0.008602    101\n",
      "0.010489     97\n",
      "0.012810    100\n",
      "0.013618     97\n",
      "0.014351     95\n",
      "0.014495     93\n",
      "0.015060     92\n",
      "0.015114     98\n",
      "0.015118    102\n",
      "0.016122     97\n",
      "0.016128     99\n",
      "0.018331    101\n",
      "0.018390     95\n",
      "0.018481    103\n",
      "           ... \n",
      "0.969015    102\n",
      "0.969465     96\n",
      "0.970052     97\n",
      "0.971268     87\n",
      "0.974926     98\n",
      "0.975578     99\n",
      "0.975705    102\n",
      "0.976349    101\n",
      "0.976365    106\n",
      "0.982441     98\n",
      "0.983389    102\n",
      "0.983391     93\n",
      "0.983893     97\n",
      "0.983893     92\n",
      "0.984096    102\n",
      "0.985122    109\n",
      "0.986444    108\n",
      "0.987446     90\n",
      "0.987475     94\n",
      "0.988113     94\n",
      "0.990474     89\n",
      "0.991466     95\n",
      "0.991614     96\n",
      "0.993669     89\n",
      "0.993966     94\n",
      "0.995637    101\n",
      "0.996500     91\n",
      "0.996512    105\n",
      "0.999563    104\n",
      "1.000000    100\n",
      "Name: feature17, dtype: int64\n",
      "feature18\n",
      "0.000000      1\n",
      "0.001259    105\n",
      "0.003431    100\n",
      "0.003441    100\n",
      "0.003476     93\n",
      "0.007590     96\n",
      "0.007597     96\n",
      "0.007609     97\n",
      "0.009668    103\n",
      "0.009670     95\n",
      "0.010185     99\n",
      "0.010186    111\n",
      "0.011719     88\n",
      "0.012548     97\n",
      "0.012809     94\n",
      "0.012835    102\n",
      "0.015944    102\n",
      "0.016011    108\n",
      "0.016989     99\n",
      "0.020128    103\n",
      "0.020542     94\n",
      "0.020580    109\n",
      "0.020580     98\n",
      "0.024342    102\n",
      "0.024402    102\n",
      "0.024587     96\n",
      "0.025415     91\n",
      "0.027005    101\n",
      "0.028496     85\n",
      "0.028546     92\n",
      "           ... \n",
      "0.976604     96\n",
      "0.976669    102\n",
      "0.976834    101\n",
      "0.977315     98\n",
      "0.980698     96\n",
      "0.980698     86\n",
      "0.980857     97\n",
      "0.980922     95\n",
      "0.980932     95\n",
      "0.981735     98\n",
      "0.982659     99\n",
      "0.982860    103\n",
      "0.983303     98\n",
      "0.983307    104\n",
      "0.984861    100\n",
      "0.984973     96\n",
      "0.986937    103\n",
      "0.986940    102\n",
      "0.989062    107\n",
      "0.989248     97\n",
      "0.989874    102\n",
      "0.993174    102\n",
      "0.993175     98\n",
      "0.997332     98\n",
      "0.997332    104\n",
      "0.998408     92\n",
      "0.998504    100\n",
      "0.998533     99\n",
      "0.999916     94\n",
      "1.000000     95\n",
      "Name: feature18, dtype: int64\n",
      "feature19\n",
      "0.000000      1\n",
      "0.000068     96\n",
      "0.000081     92\n",
      "0.000136     98\n",
      "0.001039     96\n",
      "0.001045     94\n",
      "0.001058    101\n",
      "0.002272    101\n",
      "0.002375    100\n",
      "0.003131    107\n",
      "0.003145    100\n",
      "0.007122    103\n",
      "0.008424    100\n",
      "0.008437     99\n",
      "0.008453    111\n",
      "0.011495     96\n",
      "0.012547    109\n",
      "0.012549     97\n",
      "0.016822     98\n",
      "0.016913     96\n",
      "0.017799     98\n",
      "0.017995     99\n",
      "0.020091    103\n",
      "0.021698     96\n",
      "0.021992     97\n",
      "0.022400     99\n",
      "0.025225     90\n",
      "0.025247     96\n",
      "0.025561    102\n",
      "0.025777    100\n",
      "           ... \n",
      "0.972084     96\n",
      "0.972684     95\n",
      "0.975139     93\n",
      "0.976355     96\n",
      "0.977006    101\n",
      "0.977384    104\n",
      "0.977894     94\n",
      "0.978981    101\n",
      "0.979013    104\n",
      "0.979233    103\n",
      "0.979241     99\n",
      "0.979477     98\n",
      "0.980919     98\n",
      "0.983291     93\n",
      "0.983482     96\n",
      "0.984273    102\n",
      "0.986327     89\n",
      "0.987552    101\n",
      "0.987602    105\n",
      "0.987607     88\n",
      "0.988258    104\n",
      "0.990291    102\n",
      "0.991517     91\n",
      "0.991521    104\n",
      "0.992642    102\n",
      "0.994779    101\n",
      "0.995734    102\n",
      "0.995965     95\n",
      "0.999944    101\n",
      "1.000000    101\n",
      "Name: feature19, dtype: int64\n",
      "feature20\n",
      "0.000000      1\n",
      "0.000278     96\n",
      "0.002204     92\n",
      "0.002839    104\n",
      "0.003425    100\n",
      "0.003868     90\n",
      "0.003910     91\n",
      "0.007255     98\n",
      "0.007792     93\n",
      "0.007796    103\n",
      "0.010354    104\n",
      "0.011786     96\n",
      "0.011790     94\n",
      "0.011896     98\n",
      "0.012615     99\n",
      "0.013103     94\n",
      "0.014234     99\n",
      "0.015789    108\n",
      "0.015828    107\n",
      "0.016797     98\n",
      "0.016822     89\n",
      "0.017104     90\n",
      "0.018008     96\n",
      "0.019280     90\n",
      "0.020524    100\n",
      "0.021488     93\n",
      "0.023888     98\n",
      "0.023900    103\n",
      "0.023946     94\n",
      "0.024118    100\n",
      "           ... \n",
      "0.967550     98\n",
      "0.967747     93\n",
      "0.967827     94\n",
      "0.968482     94\n",
      "0.968495    103\n",
      "0.969492     97\n",
      "0.969523    106\n",
      "0.972566     95\n",
      "0.975686     97\n",
      "0.976241     99\n",
      "0.983475     94\n",
      "0.983475     97\n",
      "0.983984    101\n",
      "0.984020     98\n",
      "0.986931     89\n",
      "0.987488     94\n",
      "0.987532     88\n",
      "0.989485     99\n",
      "0.989503    100\n",
      "0.991700     92\n",
      "0.991751    104\n",
      "0.991754     97\n",
      "0.991989    105\n",
      "0.992034     97\n",
      "0.992302     99\n",
      "0.999523     91\n",
      "0.999572    101\n",
      "0.999920     94\n",
      "0.999982     95\n",
      "1.000000     97\n",
      "Name: feature20, dtype: int64\n",
      "feature21\n",
      "0.000000e+00      1\n",
      "1.218255e-07    112\n",
      "1.617447e-03     82\n",
      "2.142454e-03     96\n",
      "2.385481e-03     97\n",
      "3.472134e-03     97\n",
      "3.718816e-03    104\n",
      "4.017212e-03    100\n",
      "4.296817e-03     95\n",
      "7.984294e-03     94\n",
      "7.984415e-03    100\n",
      "7.994024e-03     94\n",
      "8.043120e-03    101\n",
      "8.081510e-03     96\n",
      "1.198313e-02    104\n",
      "1.199735e-02     91\n",
      "1.280671e-02    106\n",
      "1.598167e-02    100\n",
      "1.601779e-02    104\n",
      "1.612967e-02    102\n",
      "1.648091e-02    103\n",
      "1.762213e-02    103\n",
      "1.814841e-02    102\n",
      "1.905181e-02    101\n",
      "1.942557e-02     92\n",
      "2.396190e-02     95\n",
      "2.398548e-02    103\n",
      "2.399943e-02    108\n",
      "2.796093e-02     87\n",
      "2.800500e-02    102\n",
      "               ... \n",
      "9.705914e-01     90\n",
      "9.716097e-01     99\n",
      "9.725009e-01    106\n",
      "9.727635e-01    103\n",
      "9.740976e-01    105\n",
      "9.742033e-01     96\n",
      "9.748053e-01     96\n",
      "9.782289e-01     96\n",
      "9.782861e-01     95\n",
      "9.782902e-01     90\n",
      "9.787268e-01    107\n",
      "9.820555e-01     96\n",
      "9.822862e-01    103\n",
      "9.825694e-01    100\n",
      "9.826230e-01     99\n",
      "9.826630e-01     94\n",
      "9.839871e-01     96\n",
      "9.849337e-01    102\n",
      "9.877813e-01    103\n",
      "9.890951e-01     98\n",
      "9.900114e-01     98\n",
      "9.900182e-01    100\n",
      "9.906986e-01    101\n",
      "9.918522e-01     94\n",
      "9.931803e-01     94\n",
      "9.940057e-01     92\n",
      "9.940349e-01     94\n",
      "9.957079e-01    103\n",
      "9.995127e-01    102\n",
      "1.000000e+00    107\n",
      "Name: feature21, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,22):\n",
    "    print train.groupby('feature' + str(i))['feature' + str(i)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data into RAM...\n",
      "reformatting data...\n",
      "10000\n",
      "86320\n",
      "[ 1.55478084 -0.35435715 -1.53061199 -0.94231004  0.37014699 -0.23755288\n",
      " -1.1931684   1.4748404  -1.39032066 -1.32913303 -0.83353394 -1.41917324\n",
      "  1.07797825 -1.02009034  0.6895715   1.13847876 -0.27244335 -0.70867389\n",
      "  1.54909635  0.38860792 -0.30387601]\n",
      "[ 0.  1.]\n",
      "data reformatting complete. Beginning evolution. Training is 86320examples, testing 10000\n",
      "nnetEvaluator testingims length: 10000\n",
      "evaluating\n",
      "running initial singleGenConsolidate\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "starting to loop\n",
      "starting a singleGenConsolidate\n",
      "half way done a singleGenConsolidate\n",
      "finished a singleGenConsolidate\n",
      "looped\n",
      "branchmultiplier: 33\n",
      "weight sharing: [False, False]\n",
      "weights number: 0\n",
      "consolidations lengths[310, 2193]\n",
      "average number of connections per neuron by layer: [1.0, 2.235483870967742]\n",
      "spacial dimension: 2\n",
      "branching by layer: [15, 18]\n",
      "beginning training\n",
      "\n",
      "testLen is [ 1.  0.]\n",
      "epoch  0 -- testing accuracy : 0.692956841666 duration: 11.0048141479s"
     ]
    }
   ],
   "source": [
    "import fulcrum\n",
    "fulcrum.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
